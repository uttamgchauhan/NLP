# -*- coding: utf-8 -*-
"""Heap's Law.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1liONslYq16OISrqJq0js-xrMaZ3HIGUJ
"""

import nltk
import matplotlib.pyplot as plt

# Download the "punkt" resource
nltk.download('punkt')

# Read the corpus or load it from a file
corpus = ['Natural Language Processing with NLTK',
             'Natural Language gets developed over the time',
             'Language Processing is very important',
             'Natural Language Processing is an important scientific field',
             'Natural Language Analysis',
             'Natural Language Processing',
             'Natural Language Understanding',
             'Natural Language Understanding']

# Tokenize the corpus into words
flat_corpus=[]
for sent in corpus:
  flat_corpus.extend(nltk.word_tokenize(sent))
print(flat_corpus)

# Initialize lists to store the vocabulary size and document length
vocab_sizes = []
doc_lengths = []

# Iterate over the words and calculate the vocabulary size and document length at each step
unique_words = set()
for i, word in enumerate(flat_corpus, 1):
    unique_words.add(word)
    vocab_sizes.append(len(unique_words))
    doc_lengths.append(i)

# Plot the Heap's Law curve
plt.plot(doc_lengths, vocab_sizes)
plt.xlabel("Document Length")
plt.ylabel("Vocabulary Size")
plt.title("Heap's Law")
plt.show()

